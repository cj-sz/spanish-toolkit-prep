{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ESPADA Spanish Annotated Dictionary Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(628298, 35)\n"
     ]
    }
   ],
   "source": [
    "# Combine the three dataframes back into a single dataframe\n",
    "# NOTE: Two entries from original dictionary manually removed containing unicode characters '\\u200e', '\\xad'\n",
    "# These appeared to be repeats of entries already present.\n",
    "df1_loaded = pd.read_csv('SpanishAnnotatedDictionary_part1.csv')\n",
    "df2_loaded = pd.read_csv('SpanishAnnotatedDictionary_part2.csv')\n",
    "df3_loaded = pd.read_csv('SpanishAnnotatedDictionary_part3.csv')\n",
    "\n",
    "espada_df = pd.concat([df1_loaded, df2_loaded, df3_loaded], ignore_index=True)\n",
    "\n",
    "print(espada_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain the set of all unique phonemes present in the dictionary. Note that all phonemes are single-lettered for simplicity, and in this dictionary there is a 1-1 correspondence between letters and their phonological counterparts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique phonemes: 36\n",
      "Unique phonemes: {'w', 'T', 'g', 'x', 'f', 'r', 'J', 'N', 'G', 'l', 'p', 'U', 'C', 'o', 'O', 'Y', 'e', 'W', 't', 'i', 'd', 'E', 'n', 'A', 's', 'B', 'm', 'u', 'I', 'S', 'b', 'R', 'j', 'a', 'k', 'D'}\n"
     ]
    }
   ],
   "source": [
    "unique_phonemes = set()\n",
    "\n",
    "for phoneme_sequence in espada_df['MainBase']:\n",
    "    phonemes = phoneme_sequence.split()\n",
    "    unique_phonemes.update(phonemes)\n",
    "\n",
    "print(f\"Total unique phonemes: {len(unique_phonemes)}\")\n",
    "print(f\"Unique phonemes: {unique_phonemes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain a list of words spanning all phonemes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of selected words: 29\n",
      "Selected words: ['a', 'aaron', 'aarón', 'aarónico', 'aaronita', 'ab', 'aba', 'ababilla', 'ababillabais', 'ababillábamos', 'ababillado', 'ababilláis', 'ababillándome', 'ababillaré', 'ababol', 'abacería', 'abacha', 'abadejo', 'abadengo', 'abajeño', 'abakuá', 'abalaustrado', 'abaleadura', 'abapó', 'abarcucé', 'abarraca', 'abarragamiento', 'abifetear', 'accha']\n"
     ]
    }
   ],
   "source": [
    "seen_phonemes = set()\n",
    "selected_words = []\n",
    "\n",
    "for index, row in espada_df.iterrows():\n",
    "    entry = row['Entry']\n",
    "    phoneme_sequence = row['MainBase']\n",
    "    \n",
    "    phonemes = set(phoneme_sequence.split())\n",
    "    \n",
    "    if not phonemes.issubset(seen_phonemes):\n",
    "        selected_words.append(entry)\n",
    "        seen_phonemes.update(phonemes)\n",
    "        \n",
    "        if seen_phonemes == unique_phonemes:\n",
    "            break\n",
    "\n",
    "print(f\"Number of selected words: {len(selected_words)}\")\n",
    "print(f\"Selected words: {selected_words}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain a set of all 1-1 grapheme-phoneme mappings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique phoneme-grapheme mappings: 229\n",
      "Phoneme-grapheme mappings: {('m', 'o'), ('r', 't'), ('á', 'A'), ('j', 'o'), ('o', 'w'), ('a', 'm'), ('ú', 'u'), ('ü', 'w'), ('o', 'p'), ('a', 'n'), ('c', 'o'), ('q', 'I'), ('s', 'i'), ('ó', 'k'), ('d', 'r'), ('h', 'O'), ('e', 'm'), ('y', 'a'), ('e', 'n'), ('j', 'x'), ('u', 'W'), ('h', 'e'), ('i', 'd'), ('r', 'k'), ('m', 'm'), ('i', 'm'), ('ñ', 'N'), ('r', 'R'), ('v', 'B'), ('u', 'g'), ('ö', 'O'), ('l', 'u'), ('r', 'u'), ('r', 'a'), ('l', 'p'), ('g', 'l'), ('r', 'p'), ('à', 'a'), ('c', 'C'), ('t', 'O'), ('u', 'E'), ('i', 'J'), ('b', 'B'), ('é', 'E'), ('q', 'e'), ('o', 'm'), ('m', 'a'), ('t', 'E'), ('m', 'u'), ('c', 'k'), ('h', 'W'), ('o', 'n'), ('c', 'T'), ('a', 'W'), ('p', 'O'), ('s', 'e'), ('h', 'S'), ('c', 'a'), ('p', 'e'), ('l', 'A'), ('o', 'J'), ('o', 'O'), ('r', 'A'), ('e', 'W'), ('à', 'A'), ('h', 'E'), ('e', 'I'), ('t', 'e'), ('a', 'l'), ('q', 'i'), ('e', 'f'), ('n', 'w'), ('ú', 'Y'), ('i', 'i'), ('è', 'E'), ('x', 's'), ('n', 'a'), ('z', 's'), ('o', 'D'), ('v', 'b'), ('i', 'I'), ('i', 'f'), ('y', 'J'), ('ó', 'O'), ('ú', 'U'), ('w', 'W'), ('y', 'p'), ('h', 'o'), ('i', 'l'), ('b', 'b'), ('q', 'E'), ('w', 'g'), ('l', 'O'), ('g', 'g'), ('r', 'O'), ('ú', 'W'), ('x', 'x'), ('ò', 'o'), ('q', 's'), ('c', 'n'), ('h', 't'), ('u', 'w'), ('e', 'e'), ('y', 'i'), ('l', 'U'), ('r', 'U'), ('i', 'O'), ('d', 'D'), ('u', 'a'), ('s', 's'), ('y', 'I'), ('w', 's'), ('h', 'C'), ('p', 's'), ('a', 'r'), ('l', 'i'), ('r', 'i'), ('ç', 's'), ('î', 'J'), ('t', 's'), ('x', 'k'), ('l', 'I'), ('p', 'o'), ('z', 'T'), ('h', 'k'), ('g', 'G'), ('h', 'w'), ('t', 'o'), ('h', 'a'), ('m', 'i'), ('a', 'w'), ('l', 'l'), ('ã', 'a'), ('i', 'W'), ('u', 't'), ('g', 'x'), ('d', 'd'), ('y', 'Y'), ('a', 's'), ('d', 'n'), ('e', 'j'), ('e', 'E'), ('t', 't'), ('c', 'I'), ('g', 'r'), ('c', 'A'), ('ü', 'U'), ('w', 'r'), ('p', 'r'), ('u', 'm'), ('l', 'Y'), ('i', 'j'), ('i', 'E'), ('e', 's'), ('o', 'W'), ('n', 'i'), ('d', 'O'), ('l', 'e'), ('c', 'l'), ('r', 'e'), ('w', 'w'), ('n', 'I'), ('u', 'k'), ('n', 'A'), ('ü', 'W'), ('s', 'a'), ('ö', 'o'), ('i', 's'), ('e', 'o'), ('w', 'u'), ('a', 't'), ('u', 'u'), ('p', 'a'), ('p', 'u'), ('u', 'p'), ('ó', 'r'), ('q', 'o'), ('o', 'E'), ('g', 'N'), ('ú', 'w'), ('í', 'I'), ('t', 'a'), ('é', 'p'), ('n', 'n'), ('u', 'U'), ('e', 't'), ('f', 'i'), ('o', 's'), ('r', 'r'), ('y', 'j'), ('f', 'f'), ('k', 'k'), ('e', 'r'), ('i', 't'), ('u', 'i'), ('i', 'x'), ('a', 'k'), ('o', 'o'), ('w', 'b'), ('u', 'I'), ('a', 'a'), ('i', 'r'), ('f', 'l'), ('l', 'E'), ('t', 'I'), ('e', 'k'), ('t', 'A'), ('e', 'w'), ('o', 't'), ('q', 'k'), ('g', 'n'), ('á', 'p'), ('i', 'k'), ('i', 'w'), ('h', 'i'), ('q', 'a'), ('s', 'J'), ('h', 'A'), ('r', 'o'), ('i', 'p'), ('u', 'J'), ('m', 's'), ('a', 'A'), ('ń', 'O'), ('u', 'e'), ('o', 'k'), ('p', 'p'), ('c', 's'), ('l', 't')}\n"
     ]
    }
   ],
   "source": [
    "phoneme_grapheme_mappings = set()\n",
    "\n",
    "# Iterate through the rows\n",
    "for index, row in espada_df.iterrows():\n",
    "    entry = row['Entry']\n",
    "    phoneme_sequence = row['MainBase']\n",
    "    \n",
    "    # Split the phoneme sequence by spaces to get individual phonemes\n",
    "    phonemes = phoneme_sequence.split()\n",
    "    \n",
    "    # Ensure the lengths of the entry and phoneme sequence match for 1-to-1 mapping\n",
    "    if len(entry) == len(phonemes):\n",
    "        for letter, phoneme in zip(entry, phonemes):\n",
    "            # Add the (letter, phoneme) tuple to the set\n",
    "            phoneme_grapheme_mappings.add((letter, phoneme))\n",
    "\n",
    "print(f\"Total unique phoneme-grapheme mappings: {len(phoneme_grapheme_mappings)}\")\n",
    "print(f\"Phoneme-grapheme mappings: {phoneme_grapheme_mappings}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output a dataframe of words, their phonemes, and the contained mappings spanning all of the mappings found in the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total spanning words: 144\n",
      "Spanning words saved to 'spanning_words.csv'\n"
     ]
    }
   ],
   "source": [
    "seen_mappings = set()\n",
    "spanning_words = []\n",
    "\n",
    "for index, row in espada_df.iterrows():\n",
    "    entry = row['Entry']\n",
    "    phoneme_sequence = row['MainBase']\n",
    "    phonemes = phoneme_sequence.split()\n",
    "    \n",
    "    # Ensure the lengths of the entry and phoneme sequence match for 1-to-1 mapping \n",
    "    if len(entry) == len(phonemes):\n",
    "        word_mappings = [(letter, phoneme) for letter, phoneme in zip(entry, phonemes)]\n",
    "        new_mappings = [(letter, phoneme) for letter, phoneme in word_mappings if (letter, phoneme) not in seen_mappings]\n",
    "        \n",
    "        if new_mappings:\n",
    "            spanning_words.append({\n",
    "                'entry': entry,\n",
    "                'phonemes': phonemes,\n",
    "                'mappings': word_mappings\n",
    "            })\n",
    "            \n",
    "            # Update the set of seen mappings\n",
    "            seen_mappings.update(new_mappings)\n",
    "            \n",
    "            # If all phoneme-grapheme mappings are found, we can exit early\n",
    "            if len(seen_mappings) == len(phoneme_grapheme_mappings):\n",
    "                break\n",
    "\n",
    "df_spanning = pd.DataFrame(spanning_words)\n",
    "df_spanning.to_csv('spanning_words.csv', index=False)\n",
    "\n",
    "print(f\"Total spanning words: {len(spanning_words)}\")\n",
    "print(f\"Spanning words saved to 'spanning_words.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output a dataframe of words, their corresponding pronunciations, and their IPA transcriptions as provided by the Spanish-IPA translator. These words also span all present phonemes and are guaranteed to have a corresponding IPA transcription as provided by the Spanish-IPA translator. (From the Spanish/Spain dictionary).\n",
    "\n",
    "Essentially once this is verified we will check the correspondence between phonemes as provided in the Spanish Annotated Dictionary and the IPA transcriptions from the translator, then map this across the entire annotated dictionary and use those IPA transcriptions as the ones in the original Annotated Dictionary do not match the IPA conventions 1-1 even in the indicated columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total spanning words: 75\n",
      "Spanning words saved to 'spanning_words_ipa_translations_ES.csv'\n"
     ]
    }
   ],
   "source": [
    "# Load the IPA translations from the JSON file with UTF-8 encoding\n",
    "with open('es_ES.json', 'r', encoding='utf-8') as file:\n",
    "    ipa_translations = json.load(file)\n",
    "\n",
    "seen_mappings = set()\n",
    "spanning_words = []\n",
    "\n",
    "for index, row in espada_df.iterrows():\n",
    "    entry = row['Entry']\n",
    "    phoneme_sequence = row['MainBase']\n",
    "    phonemes = phoneme_sequence.split()\n",
    "    \n",
    "    # Ensure the lengths of the entry and phoneme sequence match for 1-to-1 mapping \n",
    "    if len(entry) == len(phonemes):\n",
    "        word_mappings = [(letter, phoneme) for letter, phoneme in zip(entry, phonemes)]\n",
    "        new_mappings = [(letter, phoneme) for letter, phoneme in word_mappings if (letter, phoneme) not in seen_mappings]\n",
    "        \n",
    "        # Ensure the entry is in ipa_translations and only add if there are new mappings\n",
    "        if entry in ipa_translations and new_mappings:\n",
    "            # Append only if there are new mappings not seen yet\n",
    "            spanning_words.append({\n",
    "                'entry': entry,\n",
    "                'phonemes': phonemes,\n",
    "                'ipa': ipa_translations[entry]  # Add the corresponding IPA pronunciation\n",
    "            })\n",
    "            \n",
    "            # Update the set of seen mappings\n",
    "            seen_mappings.update(new_mappings)\n",
    "            \n",
    "            # If all phoneme-grapheme mappings are found, we can exit early\n",
    "            if len(seen_mappings) == len(phoneme_grapheme_mappings):\n",
    "                break\n",
    "\n",
    "# Create DataFrame without the 'mappings' column\n",
    "df_spanning = pd.DataFrame(spanning_words)\n",
    "\n",
    "# Save to CSV\n",
    "df_spanning.to_csv('spanning_words_ipa_translations_ES.csv', index=False)\n",
    "\n",
    "print(f\"Total spanning words: {len(spanning_words)}\")\n",
    "print(f\"Spanning words saved to 'spanning_words_ipa_translations_ES.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total spanning words: 75\n",
      "Spanning words saved to 'spanning_words_ipa_translations_MX.csv'\n"
     ]
    }
   ],
   "source": [
    "# SAME AS ABOVE FOR MX\n",
    "\n",
    "# Load the IPA translations from the JSON file with UTF-8 encoding\n",
    "with open('es_MX.json', 'r', encoding='utf-8') as file:\n",
    "    ipa_translations = json.load(file)\n",
    "\n",
    "seen_mappings = set()\n",
    "spanning_words = []\n",
    "\n",
    "for index, row in espada_df.iterrows():\n",
    "    entry = row['Entry']\n",
    "    phoneme_sequence = row['MainBase']\n",
    "    phonemes = phoneme_sequence.split()\n",
    "    \n",
    "    # Ensure the lengths of the entry and phoneme sequence match for 1-to-1 mapping \n",
    "    if len(entry) == len(phonemes):\n",
    "        word_mappings = [(letter, phoneme) for letter, phoneme in zip(entry, phonemes)]\n",
    "        new_mappings = [(letter, phoneme) for letter, phoneme in word_mappings if (letter, phoneme) not in seen_mappings]\n",
    "        \n",
    "        # Ensure the entry is in ipa_translations and only add if there are new mappings\n",
    "        if entry in ipa_translations and new_mappings:\n",
    "            # Append only if there are new mappings not seen yet\n",
    "            spanning_words.append({\n",
    "                'entry': entry,\n",
    "                'phonemes': phonemes,\n",
    "                'ipa': ipa_translations[entry]  # Add the corresponding IPA pronunciation\n",
    "            })\n",
    "            \n",
    "            # Update the set of seen mappings\n",
    "            seen_mappings.update(new_mappings)\n",
    "            \n",
    "            # If all phoneme-grapheme mappings are found, we can exit early\n",
    "            if len(seen_mappings) == len(phoneme_grapheme_mappings):\n",
    "                break\n",
    "\n",
    "# Create DataFrame without the 'mappings' column\n",
    "df_spanning = pd.DataFrame(spanning_words)\n",
    "\n",
    "# Save to CSV\n",
    "df_spanning.to_csv('spanning_words_ipa_translations_MX.csv', index=False)\n",
    "\n",
    "print(f\"Total spanning words: {len(spanning_words)}\")\n",
    "print(f\"Spanning words saved to 'spanning_words_ipa_translations_MX.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "628298"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(espada_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "595885"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ipa_translations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
